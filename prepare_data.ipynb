{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd ./drive/MyDrive/Colab\\ Notebooks/NLP_Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        # train_set = f.read().splitlines()\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data takes a list of strings and removes unwanted patterns\n",
    "def filter_data(data: str) -> str:\n",
    "    # data = re.sub(r\"\\( \\d+ (/ \\d+)? \\)\", \"\", data)\n",
    "    # remove all numbers\n",
    "    data = re.sub(r\"\\d+\", \"\", data)\n",
    "    # regex to remove all special characters\n",
    "    data = re.sub(r\"[][//,;\\?؟()$:\\-{}_*؛:«»`–\\\"~!]\", \"\", data)\n",
    "    # remove all english letters\n",
    "    data = re.sub(r\"[a-zA-Z]\", \"\", data)\n",
    "    # Substituting multiple spaces with single space\n",
    "    data = re.sub(r\"([^\\S\\n])+\", \" \", data, flags=re.I)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_words(data: str) -> list:\n",
    "    words = re.split(r\"\\s+\", data)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Diacritics\n",
    "KASRA = \"\\u0650\"\n",
    "DAMMA = \"\\u064F\"\n",
    "FATHA = \"\\u064E\"\n",
    "KASRATAN = \"\\u064D\"\n",
    "DAMMATAN = \"\\u064C\"\n",
    "FATHATAN = \"\\u064B\"\n",
    "SUKUN = \"\\u0652\"\n",
    "SHADDA = \"\\u0651\"\n",
    "DAMMA_SHADDA =  DAMMA + SHADDA\n",
    "SHADDA_DAMMA =  SHADDA + DAMMA\n",
    "FATHA_SHADDA =  FATHA + SHADDA\n",
    "SHADDA_FATHA =  SHADDA + FATHA\n",
    "KASRA_SHADDA =  KASRA + SHADDA\n",
    "SHADDA_KASRA =  SHADDA + KASRA\n",
    "DAMMATAN_SHADDA =  DAMMATAN + SHADDA\n",
    "SHADDA_DAMMATAN =  SHADDA + DAMMATAN\n",
    "FATHATAN_SHADDA =  FATHATAN + SHADDA\n",
    "SHADDA_FATHATAN =  SHADDA + FATHATAN\n",
    "KASRATAN_SHADDA =  KASRATAN + SHADDA\n",
    "SHADDA_KASRATAN =  SHADDA + KASRATAN\n",
    "EMPTY = \"_\"\n",
    "DIACRITICS = [KASRA, DAMMA, FATHA, KASRATAN, DAMMATAN, FATHATAN, SUKUN, SHADDA, DAMMA_SHADDA, SHADDA_DAMMA, FATHA_SHADDA, SHADDA_FATHA, KASRA_SHADDA, SHADDA_KASRA, DAMMATAN_SHADDA, SHADDA_DAMMATAN, FATHATAN_SHADDA, SHADDA_FATHATAN, KASRATAN_SHADDA, SHADDA_KASRATAN, EMPTY]\n",
    "ARABIC_ALPHABIT = \"اأآإئءبتةثجحخدذرزسشصضطظعغفقكلمنهوؤيى\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is responsible for mapping diacritics to their corresponding strings\n",
    "def diacritic_to_str(diacritic):\n",
    "    if diacritic == SHADDA:\n",
    "        diacritic = \"SHADDA\"\n",
    "    elif diacritic == KASRA:\n",
    "        diacritic = \"KASRA\"\n",
    "    elif diacritic == DAMMA:\n",
    "        diacritic = \"DAMMA\"\n",
    "    elif diacritic == FATHA:\n",
    "        diacritic = \"FATHA\"\n",
    "    elif diacritic == KASRATAN:\n",
    "        diacritic = \"KASRATAN\"\n",
    "    elif diacritic == DAMMATAN:\n",
    "        diacritic = \"DAMMATAN\"\n",
    "    elif diacritic == FATHATAN:\n",
    "        diacritic = \"FATHATAN\"\n",
    "    elif diacritic == SUKUN:\n",
    "        diacritic = \"SUKUN\"\n",
    "    elif diacritic == DAMMA_SHADDA or diacritic == SHADDA_DAMMA :\n",
    "        diacritic = \"SHADDA_DAMMA\"\n",
    "    elif diacritic == FATHA_SHADDA or diacritic == SHADDA_FATHA:\n",
    "        diacritic = \"SHADDA_FATHA\"\n",
    "    elif diacritic == KASRA_SHADDA or diacritic == SHADDA_KASRA:\n",
    "        diacritic = \"SHADDA_KASRA\"\n",
    "    elif diacritic == DAMMATAN_SHADDA or diacritic == SHADDA_DAMMATAN:\n",
    "        diacritic = \"SHADDA_DAMMATAN\"\n",
    "    elif diacritic == FATHATAN_SHADDA or diacritic == SHADDA_FATHATAN:\n",
    "        diacritic = \"SHADDA_FATHATAN\"\n",
    "    elif diacritic == KASRATAN_SHADDA or diacritic == SHADDA_KASRATAN:\n",
    "        diacritic = \"SHADDA_KASRATAN\"\n",
    "    else: # EMPTY\n",
    "        diacritic = \"_\"\n",
    "    return diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file train.txt\n",
    "training_set = read_data(\"./Dataset/train.txt\")\n",
    "# filter the data\n",
    "training_set = filter_data(training_set)\n",
    "# split the data into lines\n",
    "training_set = re.split(r\"[.،]\", training_set)\n",
    "# remove empty lines\n",
    "training_set = list(filter(None, training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file val.txt\n",
    "validation_set = read_data(\"./Dataset/val.txt\")\n",
    "# filter the data\n",
    "validation_set = filter_data(validation_set)\n",
    "# split the data into lines\n",
    "validation_set = re.split(r\"[.،]\", validation_set)\n",
    "# remove empty lines\n",
    "validation_set = list(filter(None, validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file test.txt\n",
    "test_set = read_data(\"./Dataset/test.txt\")\n",
    "# filter the data\n",
    "test_set = filter_data(test_set)\n",
    "# split the data into lines\n",
    "test_set = re.split(r\"[.،]\", test_set)\n",
    "# remove empty lines\n",
    "test_set = list(filter(None, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116499"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_set):\n",
    "    original_labels = ['' for _ in range(len(data_set))] \n",
    "    sentences = [ '' for _ in range(len(data_set))] \n",
    "    for i in range(len(data_set)):\n",
    "        line = data_set[i]\n",
    "        line_without_diacritics = []\n",
    "        line_labels = []\n",
    "        for word in line.split():\n",
    "            if word == \"\":\n",
    "                continue\n",
    "            word_without_diacritics = \"\"\n",
    "            for j in range(len(word)):\n",
    "                if j==len(word) - 2 and word[j] in DIACRITICS and word[j+1] in DIACRITICS:\n",
    "                    line_labels.append(diacritic_to_str(word[j] + word[j+1])) #lable of the word\n",
    "                    break\n",
    "                if word[j] in DIACRITICS and j != len(word) - 1:\n",
    "                    continue\n",
    "                if j == len(word) - 1:\n",
    "                    line_labels.append(diacritic_to_str(word[j])) #lable of the word\n",
    "                    if word[j] in DIACRITICS:\n",
    "                        continue\n",
    "                word_without_diacritics += word[j]\n",
    "            # if i==0:\n",
    "            #     print(word)\n",
    "            #     print(word_without_diacritics)\n",
    "\n",
    "            line_without_diacritics.append(word_without_diacritics)\n",
    "        sentences[i] = \" \".join(line_without_diacritics)\n",
    "        original_labels[i] = \" \".join(line_labels)\n",
    "        # if i==0:\n",
    "        #     print(line_without_diacritics)\n",
    "        #     print(line_labels)\n",
    "        #     print(len(line_without_diacritics)==len(line_labels))\n",
    "        #     print(sentences[i].split())\n",
    "        #     print(original_labels[i].split())\n",
    "    return sentences, original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sentences, t_labels = get_data(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_sentences, v_labels = get_data(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences, test_labels = get_data(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/test_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(test_sentences))\n",
    "with open(\"./Dataset/test_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unqiue words in a text file\n",
    "unique_words = set()\n",
    "for line in t_sentences + v_sentences:\n",
    "    for word in line.split():\n",
    "        unique_words.add(word)\n",
    "\n",
    "with open(\"./Dataset/unique_words.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(unique_words))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"UNK\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIACRITICS_LIST_OF_STRINGS = [diacritic_to_str(diacritic) for diacritic in DIACRITICS] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/unique_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(set(DIACRITICS_LIST_OF_STRINGS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unqiue labels in a text file\n",
    "# 34an a3rf lo fe label naseh wla la2\n",
    "unique_labels = set()\n",
    "for line in t_labels:\n",
    "    for label in line.split():\n",
    "        if label not in DIACRITICS_LIST_OF_STRINGS:\n",
    "            unique_labels.add(label)\n",
    "with open(\"./Dataset/unique_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
