{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        # train_set = f.read().splitlines()\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data takes a list of strings and removes unwanted patterns\n",
    "def filter_data(data: str) -> str:\n",
    "    # data = re.sub(r\"\\( \\d+ (/ \\d+)? \\)\", \"\", data)\n",
    "    # remove all numbers\n",
    "    data = re.sub(r\"\\d+\", \"\", data)\n",
    "    # regex to remove all special characters\n",
    "    data = re.sub(r\"[][//,;\\?؟()$:\\-{}_*؛:«»`–\\\"~!]\", \"\", data)\n",
    "    # remove all english letters\n",
    "    data = re.sub(r\"[a-zA-Z]\", \"\", data)\n",
    "    # Substituting multiple spaces with single space\n",
    "    data = re.sub(r\"([^\\S\\n])+\", \" \", data, flags=re.I)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_words(data: str) -> list:\n",
    "    words = re.split(r\"\\s+\", data)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Diacritics\n",
    "KASRA = \"\\u0650\"\n",
    "DAMMA = \"\\u064F\"\n",
    "FATHA = \"\\u064E\"\n",
    "KASRATAN = \"\\u064D\"\n",
    "DAMMATAN = \"\\u064C\"\n",
    "FATHATAN = \"\\u064B\"\n",
    "SUKUN = \"\\u0652\"\n",
    "SHADDA = \"\\u0651\"\n",
    "SHADDA_DAMMA =  DAMMA + SHADDA \n",
    "SHADDA_FATHA =  FATHA + SHADDA \n",
    "SHADDA_KASRA =  KASRA + SHADDA \n",
    "SHADDA_DAMMATAN =  DAMMATAN + SHADDA\n",
    "SHADDA_FATHATAN =  FATHATAN + SHADDA \n",
    "SHADDA_KASRATAN =  KASRATAN + SHADDA  \n",
    "EMPTY = \"\"\n",
    "DIACRITICS = [DAMMA, FATHA,  KASRA, DAMMATAN, FATHATAN, KASRATAN, SHADDA_DAMMA, SHADDA_FATHA,  SHADDA_KASRA, SHADDA_DAMMATAN, SHADDA_FATHATAN, SHADDA_KASRATAN, SHADDA, SUKUN, EMPTY]\n",
    "ARABIC_ALPHABIT = \"اأآإئءبتةثجحخدذرزسشصضطظعغفقكلمنهوؤيى\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is responsible for mapping diacritics to their corresponding strings\n",
    "def diacritic_to_str(diacritic):\n",
    "    if diacritic == SHADDA:\n",
    "        diacritic = \"SHADDA\"\n",
    "    elif diacritic == KASRA:\n",
    "        diacritic = \"KASRA\"\n",
    "    elif diacritic == DAMMA:\n",
    "        diacritic = \"DAMMA\"\n",
    "    elif diacritic == FATHA:\n",
    "        diacritic = \"FATHA\"\n",
    "    elif diacritic == KASRATAN:\n",
    "        diacritic = \"KASRATAN\"\n",
    "    elif diacritic == DAMMATAN:\n",
    "        diacritic = \"DAMMATAN\"\n",
    "    elif diacritic == FATHATAN:\n",
    "        diacritic = \"FATHATAN\"\n",
    "    elif diacritic == SUKUN:\n",
    "        diacritic = \"SUKUN\"\n",
    "    elif diacritic == DAMMA + SHADDA or diacritic == SHADDA +DAMMA :\n",
    "        diacritic = \"SHADDA_DAMMA\"\n",
    "    elif diacritic == FATHA + SHADDA or diacritic == SHADDA +FATHA :\n",
    "        diacritic = \"SHADDA_FATHA\"\n",
    "    elif diacritic == KASRA + SHADDA or diacritic == SHADDA + KASRA:\n",
    "        diacritic = \"SHADDA_KASRA\"\n",
    "    elif diacritic == DAMMATAN + SHADDA or diacritic == SHADDA + DAMMATAN:\n",
    "        diacritic = \"SHADDA_DAMMATAN\"\n",
    "    elif diacritic == FATHATAN + SHADDA or diacritic == SHADDA + FATHATAN:\n",
    "        diacritic = \"SHADDA_FATHATAN\"\n",
    "    elif diacritic == KASRATAN + SHADDA or diacritic == SHADDA + KASRATAN:\n",
    "        diacritic = \"SHADDA_KASRATAN\"\n",
    "    else:\n",
    "        diacritic = \" \"\n",
    "    return diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file train.txt\n",
    "training_set = read_data(\"./Dataset/train.txt\")\n",
    "# filter the data\n",
    "training_set = filter_data(training_set)\n",
    "# split the data into lines\n",
    "training_set = re.split(r\"[.،]\", training_set)\n",
    "# remove empty lines\n",
    "training_set = list(filter(None, training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116499"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = ['' for _ in range(len(training_set))] \n",
    "sentences = [ '' for _ in range(len(training_set))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_set)):\n",
    "    line = training_set[i]\n",
    "    line_without_diacritics = []\n",
    "    line_labels = []\n",
    "    for word in line.split():\n",
    "        if word == \"\":\n",
    "            continue\n",
    "        word_without_diacritics = \"\"\n",
    "        for j in range(len(word)):\n",
    "            if word[j] in DIACRITICS and j != len(word) - 1:\n",
    "                continue\n",
    "            elif word[j] in DIACRITICS and j == len(word) - 1:\n",
    "                line_labels.append(diacritic_to_str(word[j])) #lable of the word\n",
    "                continue\n",
    "            word_without_diacritics += word[j]\n",
    "        line_without_diacritics.append(word_without_diacritics)\n",
    "    sentences[i] = \" \".join(line_without_diacritics) + \" .\"\n",
    "    original_labels[i] = \" \".join(line_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(sentences))\n",
    "with open(\"./Dataset/labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(original_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
