{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd ./drive/MyDrive/Colab\\ Notebooks/NLP_Project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        # train_set = f.read().splitlines()\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data takes a list of strings and removes unwanted patterns\n",
    "def filter_data(data: str) -> str:\n",
    "    # data = re.sub(r\"\\( \\d+ (/ \\d+)? \\)\", \"\", data)\n",
    "    # remove all numbers\n",
    "    data = re.sub(r\"\\d+\", \"\", data)\n",
    "    # regex to remove all special characters\n",
    "    data = re.sub(r\"[][//,;\\?؟()$:\\-{}_*؛:«»`–\\\"~!]\", \"\", data)\n",
    "    # remove all english letters\n",
    "    data = re.sub(r\"[a-zA-Z]\", \"\", data)\n",
    "    # Substituting multiple spaces with single space\n",
    "    data = re.sub(r\"([^\\S\\n])+\", \" \", data, flags=re.I)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_words(data: str) -> list:\n",
    "    words = re.split(r\"\\s+\", data)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Diacritics\n",
    "KASRA = \"\\u0650\"\n",
    "DAMMA = \"\\u064F\"\n",
    "FATHA = \"\\u064E\"\n",
    "KASRATAN = \"\\u064D\"\n",
    "DAMMATAN = \"\\u064C\"\n",
    "FATHATAN = \"\\u064B\"\n",
    "SUKUN = \"\\u0652\"\n",
    "SHADDA = \"\\u0651\"\n",
    "DAMMA_SHADDA = DAMMA + SHADDA\n",
    "SHADDA_DAMMA = SHADDA + DAMMA\n",
    "FATHA_SHADDA = FATHA + SHADDA\n",
    "SHADDA_FATHA = SHADDA + FATHA\n",
    "KASRA_SHADDA = KASRA + SHADDA\n",
    "SHADDA_KASRA = SHADDA + KASRA\n",
    "DAMMATAN_SHADDA = DAMMATAN + SHADDA\n",
    "SHADDA_DAMMATAN = SHADDA + DAMMATAN\n",
    "FATHATAN_SHADDA = FATHATAN + SHADDA\n",
    "SHADDA_FATHATAN = SHADDA + FATHATAN\n",
    "KASRATAN_SHADDA = KASRATAN + SHADDA\n",
    "SHADDA_KASRATAN = SHADDA + KASRATAN\n",
    "EMPTY = \"_\"\n",
    "DIACRITICS = [\n",
    "    KASRA,\n",
    "    DAMMA,\n",
    "    FATHA,\n",
    "    KASRATAN,\n",
    "    DAMMATAN,\n",
    "    FATHATAN,\n",
    "    SUKUN,\n",
    "    SHADDA,\n",
    "    DAMMA_SHADDA,\n",
    "    SHADDA_DAMMA,\n",
    "    FATHA_SHADDA,\n",
    "    SHADDA_FATHA,\n",
    "    KASRA_SHADDA,\n",
    "    SHADDA_KASRA,\n",
    "    DAMMATAN_SHADDA,\n",
    "    SHADDA_DAMMATAN,\n",
    "    FATHATAN_SHADDA,\n",
    "    SHADDA_FATHATAN,\n",
    "    KASRATAN_SHADDA,\n",
    "    SHADDA_KASRATAN,\n",
    "    EMPTY,\n",
    "]\n",
    "ARABIC_ALPHABIT = \"اأآإئءبتةثجحخدذرزسشصضطظعغفقكلمنهوؤيى\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is responsible for mapping diacritics to their corresponding strings\n",
    "def diacritic_to_str(diacritic):\n",
    "    if diacritic == SHADDA:\n",
    "        diacritic = \"SHADDA\"\n",
    "    elif diacritic == KASRA:\n",
    "        diacritic = \"KASRA\"\n",
    "    elif diacritic == DAMMA:\n",
    "        diacritic = \"DAMMA\"\n",
    "    elif diacritic == FATHA:\n",
    "        diacritic = \"FATHA\"\n",
    "    elif diacritic == KASRATAN:\n",
    "        diacritic = \"KASRATAN\"\n",
    "    elif diacritic == DAMMATAN:\n",
    "        diacritic = \"DAMMATAN\"\n",
    "    elif diacritic == FATHATAN:\n",
    "        diacritic = \"FATHATAN\"\n",
    "    elif diacritic == SUKUN:\n",
    "        diacritic = \"SUKUN\"\n",
    "    elif diacritic == DAMMA_SHADDA or diacritic == SHADDA_DAMMA:\n",
    "        diacritic = \"SHADDA_DAMMA\"\n",
    "    elif diacritic == FATHA_SHADDA or diacritic == SHADDA_FATHA:\n",
    "        diacritic = \"SHADDA_FATHA\"\n",
    "    elif diacritic == KASRA_SHADDA or diacritic == SHADDA_KASRA:\n",
    "        diacritic = \"SHADDA_KASRA\"\n",
    "    elif diacritic == DAMMATAN_SHADDA or diacritic == SHADDA_DAMMATAN:\n",
    "        diacritic = \"SHADDA_DAMMATAN\"\n",
    "    elif diacritic == FATHATAN_SHADDA or diacritic == SHADDA_FATHATAN:\n",
    "        diacritic = \"SHADDA_FATHATAN\"\n",
    "    elif diacritic == KASRATAN_SHADDA or diacritic == SHADDA_KASRATAN:\n",
    "        diacritic = \"SHADDA_KASRATAN\"\n",
    "    else:  # EMPTY\n",
    "        diacritic = \"_\"\n",
    "    return diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file train.txt\n",
    "training_set = read_data(\"./Dataset/train.txt\")\n",
    "# filter the data\n",
    "training_set = filter_data(training_set)\n",
    "# split the data into lines\n",
    "training_set = re.split(r\"[.،]\", training_set)\n",
    "# remove empty lines\n",
    "training_set = list(filter(None, training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file val.txt\n",
    "validation_set = read_data(\"./Dataset/val.txt\")\n",
    "# filter the data\n",
    "validation_set = filter_data(validation_set)\n",
    "# split the data into lines\n",
    "validation_set = re.split(r\"[.،]\", validation_set)\n",
    "# remove empty lines\n",
    "validation_set = list(filter(None, validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file test.txt\n",
    "test_set = read_data(\"./Dataset/test.txt\")\n",
    "# filter the data\n",
    "test_set = filter_data(test_set)\n",
    "# split the data into lines\n",
    "test_set = re.split(r\"[.،]\", test_set)\n",
    "# remove empty lines\n",
    "test_set = list(filter(None, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116499"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_words(data_set):\n",
    "    original_labels = [\"\" for _ in range(len(data_set))]\n",
    "    sentences = [\"\" for _ in range(len(data_set))]\n",
    "    for i in range(len(data_set)):\n",
    "        line = data_set[i]\n",
    "        line_without_diacritics = []\n",
    "        line_labels = []\n",
    "        for word in line.split():\n",
    "            if word == \"\":\n",
    "                continue\n",
    "            word_without_diacritics = \"\"\n",
    "            for j in range(len(word)):\n",
    "                if (\n",
    "                    j == len(word) - 2\n",
    "                    and word[j] in DIACRITICS\n",
    "                    and word[j + 1] in DIACRITICS\n",
    "                ):\n",
    "                    line_labels.append(\n",
    "                        diacritic_to_str(word[j] + word[j + 1])\n",
    "                    )  # lable of the word\n",
    "                    break\n",
    "                if word[j] in DIACRITICS and j != len(word) - 1:\n",
    "                    continue\n",
    "                if j == len(word) - 1:\n",
    "                    line_labels.append(diacritic_to_str(word[j]))  # lable of the word\n",
    "                    if word[j] in DIACRITICS:\n",
    "                        continue\n",
    "                word_without_diacritics += word[j]\n",
    "            # if i==0:\n",
    "            #     print(word)\n",
    "            #     print(word_without_diacritics)\n",
    "\n",
    "            line_without_diacritics.append(word_without_diacritics)\n",
    "        sentences[i] = \" \".join(line_without_diacritics)\n",
    "        original_labels[i] = \" \".join(line_labels)\n",
    "        # if i==0:\n",
    "        #     print(line_without_diacritics)\n",
    "        #     print(line_labels)\n",
    "        #     print(len(line_without_diacritics)==len(line_labels))\n",
    "        #     print(sentences[i].split())\n",
    "        #     print(original_labels[i].split())\n",
    "    return sentences, original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_chars(data_set):\n",
    "    original_labels = [\"\" for _ in range(len(data_set))]\n",
    "    sentences = [\"\" for _ in range(len(data_set))]\n",
    "    for i in range(len(data_set)):\n",
    "        line = data_set[i]\n",
    "        line_without_diacritics = []\n",
    "        line_labels = []\n",
    "        for word in line.split():\n",
    "            if word == \"\":\n",
    "                continue\n",
    "            j = 0\n",
    "            while j < len(word):\n",
    "                if (\n",
    "                    j <= len(word) - 2\n",
    "                    and word[j] in DIACRITICS\n",
    "                    and word[j + 1] in DIACRITICS\n",
    "                ):\n",
    "                    line_labels.pop()\n",
    "                    line_labels.append(\n",
    "                        diacritic_to_str(word[j] + word[j + 1])\n",
    "                    )  # lable of the word\n",
    "                    j += 1\n",
    "                else:\n",
    "                    if word[j] in DIACRITICS:\n",
    "                        # pop\n",
    "                        line_labels.pop()\n",
    "                        line_labels.append(diacritic_to_str(word[j]))  # lable of the word\n",
    "                    else:\n",
    "                        line_labels.append(diacritic_to_str(word[j]))  # lable of the word\n",
    "                        line_without_diacritics.append(word[j])\n",
    "\n",
    "                j += 1\n",
    "\n",
    "        sentences[i] = \" \".join(line_without_diacritics)\n",
    "        original_labels[i] = \" \".join(line_labels)\n",
    "        # if i == 0:\n",
    "            #     print(line_without_diacritics)\n",
    "            #     print(line_labels)\n",
    "            # print(len(line_without_diacritics) == len(line_labels))\n",
    "        #     print(sentences[i].split())\n",
    "        #     print(original_labels[i].split())\n",
    "    return sentences, original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sentences, t_labels = get_data_words(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_chars, t_labels_chars = get_data_chars(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_sentences, v_labels = get_data_words(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_chars, v_labels_chars = get_data_chars(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences, test_labels = get_data_words(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chars, test_labels_chars = get_data_chars(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/characters/t_chars.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(t_chars))\n",
    "with open(\"./Dataset/characters/t_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(t_labels_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/characters/v_chars.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(v_chars))\n",
    "with open(\"./Dataset/characters/v_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(v_labels_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/characters/test_chars.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(test_chars))\n",
    "with open(\"./Dataset/characters/test_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(test_labels_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/t_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(t_sentences))\n",
    "with open(\"./Dataset/t_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(t_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/v_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(v_sentences))\n",
    "with open(\"./Dataset/v_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(v_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences and labels in a text files\n",
    "with open(\"./Dataset/test_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(test_sentences))\n",
    "with open(\"./Dataset/test_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unqiue words in a text file\n",
    "unique_words = set()\n",
    "for line in t_sentences + v_sentences:\n",
    "    for word in line.split():\n",
    "        unique_words.add(word)\n",
    "\n",
    "with open(\"./Dataset/unique_words.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(unique_words))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"UNK\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unqiue words in a text file\n",
    "unique_words = set()\n",
    "for line in t_sentences + v_sentences:\n",
    "    for word in line.split():\n",
    "        unique_words.add(word)\n",
    "\n",
    "with open(\"./Dataset/characters/unique_chars.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(unique_words))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"UNK\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIACRITICS_LIST_OF_STRINGS = [diacritic_to_str(diacritic) for diacritic in DIACRITICS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/characters/unique_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(set(DIACRITICS_LIST_OF_STRINGS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/unique_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(set(DIACRITICS_LIST_OF_STRINGS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unqiue labels in a text file\n",
    "# 34an a3rf lo fe label naseh wla la2\n",
    "unique_labels = set()\n",
    "for line in t_labels:\n",
    "    for label in line.split():\n",
    "        if label not in DIACRITICS_LIST_OF_STRINGS:\n",
    "            unique_labels.add(label)\n",
    "with open(\"./Dataset/characters/unique_labels.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3]\n",
    "l.pop()\n",
    "l.append(4)\n",
    "l.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
