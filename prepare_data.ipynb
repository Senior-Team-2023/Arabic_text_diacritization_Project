{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xr60PsovtllK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "import random as rnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU1oPNcDtllT",
        "outputId": "625f8eb4-fd32-423b-c284-9dbd2a80f2ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1zPjf1cHfdKqObemkPReffGbQHU_wotr2/NLP_Project\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd ./drive/MyDrive/Colab\\ Notebooks/NLP_Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVgFzgZQ9pn6",
        "outputId": "b6f144cf-6520-44e7-a2a3-cd20cb58270a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ي' 'ن' 'ز' 'ض' 'ظ' 'س' 'ق' 'ء' 'ئ' 'خ' 'ح' 'ر' 'ت' 'ف' 'و' 'غ' 'ل' 'ه'\n",
            " 'ب' 'د' 'إ' 'م' 'ج' 'ش' 'ع' 'ا' 'ك' 'ؤ' 'ص' 'ى' 'ذ' 'ث' 'آ' 'ط' 'أ' 'ة'\n",
            " 'UNK' '<pad>']\n",
            "38\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the path to your .pickle file\n",
        "pickle_file_path = './Pickle files/arabic_letters.pickle'\n",
        "\n",
        "# Open the file in binary mode and read the content\n",
        "with open(pickle_file_path, 'rb') as file:\n",
        "    # Load the content from the pickle file\n",
        "    data = pickle.load(file)\n",
        "\n",
        "# Print the content\n",
        "data = np.array(list(data))\n",
        "data = np.append(data, 'UNK')\n",
        "data = np.append(data, '<pad>')\n",
        "arabic_letters = data\n",
        "print(data)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0tOhJYD5tllZ"
      },
      "outputs": [],
      "source": [
        "def read_data(path: str) -> str:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        # train_set = f.read().splitlines()\n",
        "        return f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r41gXQa1tlla"
      },
      "outputs": [],
      "source": [
        "# filter data takes a list of strings and removes unwanted patterns\n",
        "def filter_data(data: str) -> str:\n",
        "    # data = re.sub(r\"\\( \\d+ (/ \\d+)? \\)\", \"\", data)\n",
        "    # remove all numbers\n",
        "    data = re.sub(r\"\\d+\", \"\", data)\n",
        "    # regex to remove all special characters\n",
        "    data = re.sub(r\"[][//,;\\?؟()$:\\-{}_*؛:«»`–\\\"~!']\", \"\", data)\n",
        "    # remove all english letters\n",
        "    data = re.sub(r\"[a-zA-Z]\", \"\", data)\n",
        "    # Substituting multiple spaces with single space\n",
        "    data = re.sub(r\"([^\\S\\n])+\", \" \", data, flags=re.I)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V2ABtXLAtllb"
      },
      "outputs": [],
      "source": [
        "def split_data_to_words(data: str) -> list:\n",
        "    words = re.split(r\"\\s+\", data)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FLhaIqb_tllc"
      },
      "outputs": [],
      "source": [
        "# Define Diacritics\n",
        "KASRA = \"\\u0650\"\n",
        "DAMMA = \"\\u064F\"\n",
        "FATHA = \"\\u064E\"\n",
        "KASRATAN = \"\\u064D\"\n",
        "DAMMATAN = \"\\u064C\"\n",
        "FATHATAN = \"\\u064B\"\n",
        "SUKUN = \"\\u0652\"\n",
        "SHADDA = \"\\u0651\"\n",
        "DAMMA_SHADDA = DAMMA + SHADDA\n",
        "SHADDA_DAMMA = SHADDA + DAMMA\n",
        "FATHA_SHADDA = FATHA + SHADDA\n",
        "SHADDA_FATHA = SHADDA + FATHA\n",
        "KASRA_SHADDA = KASRA + SHADDA\n",
        "SHADDA_KASRA = SHADDA + KASRA\n",
        "DAMMATAN_SHADDA = DAMMATAN + SHADDA\n",
        "SHADDA_DAMMATAN = SHADDA + DAMMATAN\n",
        "FATHATAN_SHADDA = FATHATAN + SHADDA\n",
        "SHADDA_FATHATAN = SHADDA + FATHATAN\n",
        "KASRATAN_SHADDA = KASRATAN + SHADDA\n",
        "SHADDA_KASRATAN = SHADDA + KASRATAN\n",
        "EMPTY = \"_\"\n",
        "PAD_LABLE = \"pad\"\n",
        "DIACRITICS = [\n",
        "    KASRA,\n",
        "    DAMMA,\n",
        "    FATHA,\n",
        "    KASRATAN,\n",
        "    DAMMATAN,\n",
        "    FATHATAN,\n",
        "    SUKUN,\n",
        "    SHADDA,\n",
        "    DAMMA_SHADDA,\n",
        "    SHADDA_DAMMA,\n",
        "    FATHA_SHADDA,\n",
        "    SHADDA_FATHA,\n",
        "    KASRA_SHADDA,\n",
        "    SHADDA_KASRA,\n",
        "    DAMMATAN_SHADDA,\n",
        "    SHADDA_DAMMATAN,\n",
        "    FATHATAN_SHADDA,\n",
        "    SHADDA_FATHATAN,\n",
        "    KASRATAN_SHADDA,\n",
        "    SHADDA_KASRATAN,\n",
        "    EMPTY,\n",
        "    PAD_LABLE,\n",
        "]\n",
        "ARABIC_ALPHABIT = \"اأآإئءبتةثجحخدذرزسشصضطظعغفقكلمنهوؤيى\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8pcjq-Dxtlli"
      },
      "outputs": [],
      "source": [
        "# This function is responsible for mapping diacritics to their corresponding strings\n",
        "def diacritic_to_str(diacritic):\n",
        "    if diacritic == SHADDA:\n",
        "        diacritic = \"SHADDA\"\n",
        "    elif diacritic == KASRA:\n",
        "        diacritic = \"KASRA\"\n",
        "    elif diacritic == DAMMA:\n",
        "        diacritic = \"DAMMA\"\n",
        "    elif diacritic == FATHA:\n",
        "        diacritic = \"FATHA\"\n",
        "    elif diacritic == KASRATAN:\n",
        "        diacritic = \"KASRATAN\"\n",
        "    elif diacritic == DAMMATAN:\n",
        "        diacritic = \"DAMMATAN\"\n",
        "    elif diacritic == FATHATAN:\n",
        "        diacritic = \"FATHATAN\"\n",
        "    elif diacritic == SUKUN:\n",
        "        diacritic = \"SUKUN\"\n",
        "    elif diacritic == DAMMA_SHADDA or diacritic == SHADDA_DAMMA:\n",
        "        diacritic = \"SHADDA_DAMMA\"\n",
        "    elif diacritic == FATHA_SHADDA or diacritic == SHADDA_FATHA:\n",
        "        diacritic = \"SHADDA_FATHA\"\n",
        "    elif diacritic == KASRA_SHADDA or diacritic == SHADDA_KASRA:\n",
        "        diacritic = \"SHADDA_KASRA\"\n",
        "    elif diacritic == DAMMATAN_SHADDA or diacritic == SHADDA_DAMMATAN:\n",
        "        diacritic = \"SHADDA_DAMMATAN\"\n",
        "    elif diacritic == FATHATAN_SHADDA or diacritic == SHADDA_FATHATAN:\n",
        "        diacritic = \"SHADDA_FATHATAN\"\n",
        "    elif diacritic == KASRATAN_SHADDA or diacritic == SHADDA_KASRATAN:\n",
        "        diacritic = \"SHADDA_KASRATAN\"\n",
        "    elif diacritic==\"pad\":\n",
        "      diacritic = \"pad\"\n",
        "    else:  # EMPTY\n",
        "        diacritic = \"_\"\n",
        "    return diacritic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "syMxegE0tllj"
      },
      "outputs": [],
      "source": [
        "# read the file train.txt\n",
        "training_set = read_data(\"./Dataset/train.txt\")\n",
        "# filter the data\n",
        "training_set = filter_data(training_set)\n",
        "# split the data into lines\n",
        "training_set = re.split(r\"[.،]\", training_set)\n",
        "# remove empty lines\n",
        "training_set = list(filter(None, training_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NaDB7nPotllk"
      },
      "outputs": [],
      "source": [
        "# read the file val.txt\n",
        "validation_set = read_data(\"./Dataset/val.txt\")\n",
        "# filter the data\n",
        "validation_set = filter_data(validation_set)\n",
        "# split the data into lines\n",
        "validation_set = re.split(r\"[.،]\", validation_set)\n",
        "# remove empty lines\n",
        "validation_set = list(filter(None, validation_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AnJg-4uRtllq"
      },
      "outputs": [],
      "source": [
        "# read the file test.txt\n",
        "test_set = read_data(\"./Dataset/test_no_diacritics_3.txt\")\n",
        "# test_set = read_data(\"./Dataset/test.txt\")\n",
        "# test_set = read_data(\"./Dataset/test2.txt\")\n",
        "# filter the data\n",
        "test_set = filter_data(test_set)\n",
        "# split the data into lines\n",
        "test_set = re.split(r\"[.،]\", test_set)\n",
        "# remove empty lines\n",
        "test_set = list(filter(None, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MILcslqstllr",
        "outputId": "23b8811f-4eac-4ff4-dec9-0f977bda30b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "116499"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IgPhDps4tllt"
      },
      "outputs": [],
      "source": [
        "def get_data_words(data_set):\n",
        "    original_labels = [\"\" for _ in range(len(data_set))]\n",
        "    sentences = [\"\" for _ in range(len(data_set))]\n",
        "    for i in range(len(data_set)):\n",
        "        line = data_set[i]\n",
        "        line_without_diacritics = []\n",
        "        line_labels = []\n",
        "        for word in line.split():\n",
        "            if word == \"\":\n",
        "                continue\n",
        "            word_without_diacritics = \"\"\n",
        "            for j in range(len(word)):\n",
        "                if (\n",
        "                    j == len(word) - 2\n",
        "                    and word[j] in DIACRITICS\n",
        "                    and word[j + 1] in DIACRITICS\n",
        "                ):\n",
        "                    line_labels.append(\n",
        "                        diacritic_to_str(word[j] + word[j + 1])\n",
        "                    )  # lable of the word\n",
        "                    break\n",
        "                if word[j] in DIACRITICS and j != len(word) - 1:\n",
        "                    continue\n",
        "                if j == len(word) - 1:\n",
        "                    line_labels.append(diacritic_to_str(word[j]))  # lable of the word\n",
        "                    if word[j] in DIACRITICS:\n",
        "                        continue\n",
        "                word_without_diacritics += word[j]\n",
        "            # if i==0:\n",
        "            #     print(word)\n",
        "            #     print(word_without_diacritics)\n",
        "\n",
        "            line_without_diacritics.append(word_without_diacritics)\n",
        "        sentences[i] = \" \".join(line_without_diacritics)\n",
        "        original_labels[i] = \" \".join(line_labels)\n",
        "        # if i==0:\n",
        "        #     print(line_without_diacritics)\n",
        "        #     print(line_labels)\n",
        "        #     print(len(line_without_diacritics)==len(line_labels))\n",
        "        #     print(sentences[i].split())\n",
        "        #     print(original_labels[i].split())\n",
        "    sentences = list(filter(None, sentences))\n",
        "    original_labels = list(filter(None, original_labels))\n",
        "    return sentences, original_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-_DfOdl1tllw"
      },
      "outputs": [],
      "source": [
        "def get_data_chars(data_set):\n",
        "    original_labels = [\"\" for _ in range(len(data_set))]\n",
        "    sentences = [\"\" for _ in range(len(data_set))]\n",
        "    for i in range(len(data_set)):\n",
        "        line = data_set[i]\n",
        "        line_without_diacritics = []\n",
        "        line_labels = []\n",
        "        for word in line.split():\n",
        "            if word == \"\":\n",
        "                continue\n",
        "            j = 0\n",
        "            while j < len(word):\n",
        "                if (\n",
        "                    j <= len(word) - 2\n",
        "                    and word[j] in DIACRITICS\n",
        "                    and word[j + 1] in DIACRITICS\n",
        "                ):\n",
        "                    line_labels.pop()\n",
        "                    line_labels.append(\n",
        "                        diacritic_to_str(word[j] + word[j + 1])\n",
        "                    )  # lable of the word\n",
        "                    j += 1\n",
        "                else:\n",
        "                    if word[j] in DIACRITICS:\n",
        "                        # pop\n",
        "                        line_labels.pop()\n",
        "                        line_labels.append(diacritic_to_str(word[j]))  # lable of the word\n",
        "                    else:\n",
        "                        line_labels.append(diacritic_to_str(word[j]))  # lable of the word\n",
        "                        line_without_diacritics.append(word[j])\n",
        "\n",
        "                j += 1\n",
        "\n",
        "        sentences[i] = \" \".join(line_without_diacritics)\n",
        "        original_labels[i] = \" \".join(line_labels)\n",
        "        # if i == 0:\n",
        "            #     print(line_without_diacritics)\n",
        "            #     print(line_labels)\n",
        "            # print(len(line_without_diacritics) == len(line_labels))\n",
        "        #     print(sentences[i].split())\n",
        "        #     print(original_labels[i].split())\n",
        "    sentences = list(filter(None, sentences))\n",
        "    original_labels = list(filter(None, original_labels))\n",
        "\n",
        "    return sentences, original_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pgpUitpRtllx"
      },
      "outputs": [],
      "source": [
        "t_sentences, t_labels = get_data_words(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iMJB5r5gtllx"
      },
      "outputs": [],
      "source": [
        "t_chars, t_labels_chars = get_data_chars(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GrozehEStlly"
      },
      "outputs": [],
      "source": [
        "v_sentences, v_labels = get_data_words(validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cmEyTxWQtlly"
      },
      "outputs": [],
      "source": [
        "v_chars, v_labels_chars = get_data_chars(validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7EsgjbqFtllz"
      },
      "outputs": [],
      "source": [
        "test_sentences, test_labels = get_data_words(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mRn1BthOtllz"
      },
      "outputs": [],
      "source": [
        "test_chars, test_labels_chars = get_data_chars(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4kksiF3Affc",
        "outputId": "076b116f-55e7-442f-8b50-9afb56e8b35e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_chars) == len(test_labels_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOIFUBW51Qhp"
      },
      "outputs": [],
      "source": [
        "for l in test_chars:\n",
        "  if l==\" \" or l==\"\" or l==\"\\n\":\n",
        "    print(\"empty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcDTtKPZxpTH"
      },
      "outputs": [],
      "source": [
        "number_of_chars = 0\n",
        "for l in test_chars:\n",
        "  number_of_chars +=len(l.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFsAXxbWys51",
        "outputId": "ae9e1ba9-be8f-45e8-b8bd-67f54299282c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "number_of_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQo2XrfD2PZ_",
        "outputId": "899f86cc-3792-476e-c675-de4c84935a43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\\n\".join(test_chars).split(\"\\n\") == test_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0AZtKGvVtllz"
      },
      "outputs": [],
      "source": [
        "# save the sentences and labels in a text files\n",
        "with open(\"./Dataset/new_new_characters/t_chars.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(t_chars))\n",
        "with open(\"./Dataset/new_new_characters/t_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(t_labels_chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jY9zvCGlukhz"
      },
      "outputs": [],
      "source": [
        "# save the sentences and labels in a text files\n",
        "with open(\"./Dataset/new_new_characters/v_chars.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(v_chars))\n",
        "with open(\"./Dataset/new_new_characters/v_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(v_labels_chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VYZyqjtxul8V"
      },
      "outputs": [],
      "source": [
        "# save the sentences and labels in a text files\n",
        "with open(\"./Dataset/new_new_characters/test_chars_3.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(test_chars))\n",
        "with open(\"./Dataset/new_new_characters/test_labels_3.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(test_labels_chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR_MRDOutll0",
        "outputId": "619d3005-13c7-4987-d371-d111c111ffaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38\n"
          ]
        }
      ],
      "source": [
        "# save the unqiue words in a text file\n",
        "unique_chars = arabic_letters\n",
        "# unique_chars = []\n",
        "# for line in t_chars + v_chars:\n",
        "#     for c in line.split():\n",
        "#         if c not in unique_chars:\n",
        "#           unique_chars.append(c)\n",
        "print(len(unique_chars))\n",
        "with open(\"./Dataset/new_characters/unique_chars.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(unique_chars))\n",
        "    # f.write(\"\\n\")\n",
        "    # f.write(\"UNK\")\n",
        "    # f.write(\"\\n\")\n",
        "    # f.write(\"<pad>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTjTPbARY8Ia",
        "outputId": "e99844d4-99c5-48c3-92d1-a03cde5064b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'َ': 0, 'ً': 1, 'ُ': 2, 'ٌ': 3, 'ِ': 4, 'ٍ': 5, 'ْ': 6, 'ّ': 7, 'َّ': 8, 'ًّ': 9, 'ُّ': 10, 'ٌّ': 11, 'ِّ': 12, 'ٍّ': 13, '': 14}\n",
            "15\n"
          ]
        }
      ],
      "source": [
        "# Specify the path to your .pickle file\n",
        "pickle_file_path = './Pickle files/diacritic2id.pickle'\n",
        "\n",
        "# Open the file in binary mode and read the content\n",
        "with open(pickle_file_path, 'rb') as file:\n",
        "    # Load the content from the pickle file\n",
        "    data = pickle.load(file)\n",
        "print(data)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqXbXLIntll0",
        "outputId": "97cc1839-6919-4e20-8b31-50048626dc52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['FATHA',\n",
              " 'FATHATAN',\n",
              " 'DAMMA',\n",
              " 'DAMMATAN',\n",
              " 'KASRA',\n",
              " 'KASRATAN',\n",
              " 'SUKUN',\n",
              " 'SHADDA',\n",
              " 'SHADDA_FATHA',\n",
              " 'SHADDA_FATHATAN',\n",
              " 'SHADDA_DAMMA',\n",
              " 'SHADDA_DAMMATAN',\n",
              " 'SHADDA_KASRA',\n",
              " 'SHADDA_KASRATAN',\n",
              " '_',\n",
              " 'pad']"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DIACRITICS_LIST_OF_STRINGS = [diacritic_to_str(diacritic) for diacritic in data.keys()]\n",
        "DIACRITICS_LIST_OF_STRINGS.append(\"pad\")\n",
        "DIACRITICS_LIST_OF_STRINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_Xff4ya4qXH",
        "outputId": "7aa1d993-c69d-424f-d492-f00fd61bd3b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(DIACRITICS_LIST_OF_STRINGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsFmdQ4Vtll0"
      },
      "outputs": [],
      "source": [
        "with open(\"./Dataset/new_new_characters/unique_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(DIACRITICS_LIST_OF_STRINGS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysLqea7y-qtZ",
        "outputId": "6af299ad-1292-47d3-fcd6-69c30316b5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FATHA : 0\n",
            "FATHATAN : 1\n",
            "DAMMA : 2\n",
            "DAMMATAN : 3\n",
            "KASRA : 4\n",
            "KASRATAN : 5\n",
            "SUKUN : 6\n",
            "SHADDA : 7\n",
            "SHADDA_FATHA : 8\n",
            "SHADDA_FATHATAN : 9\n",
            "SHADDA_DAMMA : 10\n",
            "SHADDA_DAMMATAN : 11\n",
            "SHADDA_KASRA : 12\n",
            "SHADDA_KASRATAN : 13\n",
            "_ : 14\n"
          ]
        }
      ],
      "source": [
        "for k,v in data.items():\n",
        "  print(diacritic_to_str(k),\":\",v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyJkTm2hvBRb"
      },
      "outputs": [],
      "source": [
        "# save the sentences and labels in a text files\n",
        "with open(\"./Dataset/t_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(t_sentences))\n",
        "with open(\"./Dataset/t_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(t_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06Fx3j1OvD0L"
      },
      "outputs": [],
      "source": [
        "# save the sentences and labels in a text files\n",
        "with open(\"./Dataset/v_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(v_sentences))\n",
        "with open(\"./Dataset/v_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(v_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yVT-rNAvF1z"
      },
      "outputs": [],
      "source": [
        "# save the sentences and labels in a text files\n",
        "with open(\"./Dataset/test_sentences.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(test_sentences))\n",
        "with open(\"./Dataset/test_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRuE9e4ftll1"
      },
      "outputs": [],
      "source": [
        "# save the unqiue labels in a text file\n",
        "# 34an a3rf lo fe label naseh wla la2\n",
        "unique_labels = []\n",
        "for line in t_labels:\n",
        "    for label in line.split():\n",
        "        if label not in DIACRITICS_LIST_OF_STRINGS:\n",
        "            unique_labels.append(label)\n",
        "with open(\"./Dataset/characters/unique_labels.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(unique_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE8W12o0vSIr"
      },
      "outputs": [],
      "source": [
        "# save the unqiue words in a text file\n",
        "unique_words = []\n",
        "for line in t_sentences + v_sentences:\n",
        "    for word in line.split():\n",
        "        if word not in unique_words:\n",
        "            unique_words.append(word)\n",
        "\n",
        "with open(\"./Dataset/unique_words.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(unique_words))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"UNK\")\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"<pad>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_OlKpn2TKP2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
